{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fusion Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Models and Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "Zlm73fNmXNhC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from fastapi import APIRouter, HTTPException\n",
        "from fastapi.responses import JSONResponse\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Attention Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=4, dropout=0.1):\n",
        "        super(CrossAttentionBlock, self).__init__()\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "        self.ff_norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, query, key_value):\n",
        "        attn_output, _ = self.attn(query, key_value, key_value)\n",
        "        out = self.norm(query + attn_output)\n",
        "        out_ff = self.ff_norm(out + self.ff(out))\n",
        "        return out_ff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adaptive Modality Selector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class AdaptiveSelector(nn.Module):\n",
        "    def __init__(self, embed_dim, num_modalities=3):\n",
        "        super(AdaptiveSelector, self).__init__()\n",
        "        self.fc = nn.Linear(embed_dim * num_modalities, num_modalities)\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        combined = torch.cat(embeddings, dim=-1)\n",
        "        weights = F.softmax(self.fc(combined), dim=-1)\n",
        "        return weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class FusionModel(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=4, num_slots=24):\n",
        "        super(FusionModel, self).__init__()\n",
        "        self.user_content_attn = CrossAttentionBlock(embed_dim, num_heads)\n",
        "        self.user_context_attn = CrossAttentionBlock(embed_dim, num_heads)\n",
        "        self.content_context_attn = CrossAttentionBlock(embed_dim, num_heads)\n",
        "        self.selector = AdaptiveSelector(embed_dim, num_modalities=3)\n",
        "        self.fc_out = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, num_slots)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_emb, content_emb, context_emb):\n",
        "        user = user_emb.unsqueeze(1)\n",
        "        content = content_emb.unsqueeze(1)\n",
        "        context = context_emb.unsqueeze(1)\n",
        "\n",
        "        user_refined = self.user_content_attn(user, content) + self.user_context_attn(user, context)\n",
        "        content_refined = self.user_content_attn(content, user) + self.content_context_attn(content, context)\n",
        "        context_refined = self.user_context_attn(context, user) + self.content_context_attn(context, content)\n",
        "\n",
        "        user_refined = user_refined.squeeze(1)\n",
        "        content_refined = content_refined.squeeze(1)\n",
        "        context_refined = context_refined.squeeze(1)\n",
        "\n",
        "        weights = self.selector([user_refined, content_refined, context_refined])\n",
        "        fused_emb = (\n",
        "            weights[:, 0:1] * user_refined +\n",
        "            weights[:, 1:2] * content_refined +\n",
        "            weights[:, 2:3] * context_refined\n",
        "        )\n",
        "\n",
        "        slot_scores = self.fc_out(fused_emb)\n",
        "        heatmap = torch.sigmoid(slot_scores)\n",
        "        return heatmap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "XnjyAVKJRj35"
      },
      "outputs": [],
      "source": [
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, user_file,video_file, metadata_file):\n",
        "        # Load input embeddings\n",
        "        df_input_vid = pd.read_csv(video_file)\n",
        "        df_input_user = pd.read_csv(user_file)\n",
        "        self.user_embeddings = df_input_user.iloc[:, 1:].values.astype(np.float32)\n",
        "        self.video_embeddings = df_input_vid.iloc[:,:384].values.astype(np.float32)\n",
        "        self.slot_ids = df_input_vid[\"slot_id\"].values.astype(np.int64)\n",
        "\n",
        "        # Load metadata embeddings (fixed per row)\n",
        "        df_metadata = pd.read_csv(metadata_file)\n",
        "        self.metadata_embeddings = df_metadata.iloc[:, 1:].values.astype(np.float32)\n",
        "\n",
        "        # Ensure alignment (row i in metadata corresponds to row i in input)\n",
        "        assert self.metadata_embeddings.shape[0] == len(self.user_embeddings), \"Metadata and input row count mismatch\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_emb = torch.tensor(self.user_embeddings[idx])\n",
        "        video_emb = torch.tensor(self.video_embeddings[idx])\n",
        "        metadata_emb = torch.tensor(self.metadata_embeddings[idx])\n",
        "        slot_id = torch.tensor(self.slot_ids[idx])\n",
        "        return user_emb, video_emb, metadata_emb, slot_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "vXrdIoOSXfdN",
        "outputId": "586eec27-0b95-433c-ccac-6922fbaf7660"
      },
      "outputs": [],
      "source": [
        "# df_meta = pd.read_csv('metadata_embeddings.csv')\n",
        "# df_meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po3xLbdFYHWJ",
        "outputId": "0a561bf8-7a5a-4e17-bdd7-500de65440c2"
      },
      "outputs": [],
      "source": [
        "# # Preprocessing the csv file\n",
        "\n",
        "# import pandas as pd\n",
        "# import ast\n",
        "\n",
        "# # Load the CSV\n",
        "# df = pd.read_csv(\"channel_embedding_results.csv\")\n",
        "\n",
        "# # Convert the string list in embedding_response back to a Python list\n",
        "# df[\"embedding_response\"] = df[\"embedding_response\"].apply(ast.literal_eval)\n",
        "\n",
        "# # Expand the list into separate columns\n",
        "# embeddings_df = pd.DataFrame(df[\"embedding_response\"].tolist())\n",
        "\n",
        "# # Rename columns as embedding_0, embedding_1, ...\n",
        "# embeddings_df = embeddings_df.add_prefix(\"embedding_\")\n",
        "\n",
        "# # # Concatenate channel_id with the expanded embeddings\n",
        "# # final_df = pd.concat([df[\"channel_id\"], embeddings_df], axis=1)\n",
        "\n",
        "# # Save to new CSV\n",
        "# embeddings_df.to_csv(\"channel_embeddings_expanded.csv\", index=False)\n",
        "\n",
        "# print(\"Expanded CSV saved as channel_embeddings_expanded.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "IaCr11S0adLK"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv('channel_embeddings_expanded.csv')\n",
        "\n",
        "\n",
        "\n",
        "row_to_duplicate = df.iloc[[0]]   # keep as DataFrame\n",
        "\n",
        "# Duplicate it 100 times\n",
        "duplicated_rows = pd.concat([row_to_duplicate] * 100, ignore_index=True)\n",
        "\n",
        "# Append duplicated rows back to original DataFrame\n",
        "df_extended = pd.concat([df, duplicated_rows], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "lCiQvciKowrO",
        "outputId": "c6bd9cce-4beb-4cb6-f3a1-69aab93798de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_id</th>\n",
              "      <th>embedding_0</th>\n",
              "      <th>embedding_1</th>\n",
              "      <th>embedding_2</th>\n",
              "      <th>embedding_3</th>\n",
              "      <th>embedding_4</th>\n",
              "      <th>embedding_5</th>\n",
              "      <th>embedding_6</th>\n",
              "      <th>embedding_7</th>\n",
              "      <th>embedding_8</th>\n",
              "      <th>...</th>\n",
              "      <th>embedding_375</th>\n",
              "      <th>embedding_376</th>\n",
              "      <th>embedding_377</th>\n",
              "      <th>embedding_378</th>\n",
              "      <th>embedding_379</th>\n",
              "      <th>embedding_380</th>\n",
              "      <th>embedding_381</th>\n",
              "      <th>embedding_382</th>\n",
              "      <th>embedding_383</th>\n",
              "      <th>slot_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>UCAo_wAxH1WT6rFmK5yCd1Cg</td>\n",
              "      <td>0.047816</td>\n",
              "      <td>0.066386</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.017043</td>\n",
              "      <td>-0.019379</td>\n",
              "      <td>0.012575</td>\n",
              "      <td>0.140922</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014132</td>\n",
              "      <td>-0.038559</td>\n",
              "      <td>0.04619</td>\n",
              "      <td>-0.046468</td>\n",
              "      <td>0.093365</td>\n",
              "      <td>0.088916</td>\n",
              "      <td>-0.026842</td>\n",
              "      <td>-0.068403</td>\n",
              "      <td>0.104807</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows × 386 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   channel_id  embedding_0  embedding_1  embedding_2  \\\n",
              "0    UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "1    UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "2    UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "3    UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "4    UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "..                        ...          ...          ...          ...   \n",
              "96   UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "97   UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "98   UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "99   UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "100  UCAo_wAxH1WT6rFmK5yCd1Cg     0.047816     0.066386     -0.03279   \n",
              "\n",
              "     embedding_3  embedding_4  embedding_5  embedding_6  embedding_7  \\\n",
              "0       0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "1       0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "2       0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "3       0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "4       0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "96      0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "97      0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "98      0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "99      0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "100     0.017043    -0.019379     0.012575     0.140922       0.0582   \n",
              "\n",
              "     embedding_8  ...  embedding_375  embedding_376  embedding_377  \\\n",
              "0       0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "1       0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "2       0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "3       0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "4       0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "..           ...  ...            ...            ...            ...   \n",
              "96      0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "97      0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "98      0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "99      0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "100     0.011558  ...       0.014132      -0.038559        0.04619   \n",
              "\n",
              "     embedding_378  embedding_379  embedding_380  embedding_381  \\\n",
              "0        -0.046468       0.093365       0.088916      -0.026842   \n",
              "1        -0.046468       0.093365       0.088916      -0.026842   \n",
              "2        -0.046468       0.093365       0.088916      -0.026842   \n",
              "3        -0.046468       0.093365       0.088916      -0.026842   \n",
              "4        -0.046468       0.093365       0.088916      -0.026842   \n",
              "..             ...            ...            ...            ...   \n",
              "96       -0.046468       0.093365       0.088916      -0.026842   \n",
              "97       -0.046468       0.093365       0.088916      -0.026842   \n",
              "98       -0.046468       0.093365       0.088916      -0.026842   \n",
              "99       -0.046468       0.093365       0.088916      -0.026842   \n",
              "100      -0.046468       0.093365       0.088916      -0.026842   \n",
              "\n",
              "     embedding_382  embedding_383  slot_id  \n",
              "0        -0.068403       0.104807       45  \n",
              "1        -0.068403       0.104807       45  \n",
              "2        -0.068403       0.104807       45  \n",
              "3        -0.068403       0.104807       45  \n",
              "4        -0.068403       0.104807       45  \n",
              "..             ...            ...      ...  \n",
              "96       -0.068403       0.104807       45  \n",
              "97       -0.068403       0.104807       45  \n",
              "98       -0.068403       0.104807       45  \n",
              "99       -0.068403       0.104807       45  \n",
              "100      -0.068403       0.104807       45  \n",
              "\n",
              "[101 rows x 386 columns]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vids_emb = df_extended.copy()\n",
        "df_vids_emb['slot_id'] = 45\n",
        "df_vids_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "yf5vqDKxpCQP"
      },
      "outputs": [],
      "source": [
        "# df_vids_emb.to_csv(\"vid_embs_expanded.csv\", index=False)\n",
        "df_extended.to_csv(\"user_embs_expanded.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqYS6dBsW3dE",
        "outputId": "07ebaf8f-5a5b-465a-cbac-b929667fbf31"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Hyperparameters\n",
        "# ---------------------------\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "EMBED_DIM = 384\n",
        "NUM_HEADS = 4\n",
        "NUM_SLOTS = 168\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Metadata and input row count mismatch",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mFusionDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_embs_expanded.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvid_embs_expanded.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata_embeddings_expanded.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Split dataset (80/10/10)\u001b[39;00m\n\u001b[32m      7\u001b[39m train_idx, temp_idx = train_test_split(np.arange(\u001b[38;5;28mlen\u001b[39m(dataset)), test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[147]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mFusionDataset.__init__\u001b[39m\u001b[34m(self, user_file, video_file, metadata_file)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.metadata_embeddings = df_metadata.iloc[:, \u001b[32m1\u001b[39m:].values.astype(np.float32)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Ensure alignment (row i in metadata corresponds to row i in input)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata_embeddings.shape[\u001b[32m0\u001b[39m] == \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.user_embeddings), \u001b[33m\"\u001b[39m\u001b[33mMetadata and input row count mismatch\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: Metadata and input row count mismatch"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---------------------------\n",
        "# Load Dataset\n",
        "# ---------------------------\n",
        "dataset = FusionDataset(\"user_embs_expanded.csv\", \"vid_embs_expanded.csv\",\"metadata_embeddings_expanded.csv\")\n",
        "\n",
        "# Split dataset (80/10/10)\n",
        "train_idx, temp_idx = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state=42)\n",
        "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
        "\n",
        "train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
        "test_subset = torch.utils.data.Subset(dataset, test_idx)\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ---------------------------\n",
        "# Initialize Model\n",
        "# ---------------------------\n",
        "\n",
        "model = FusionModel(embed_dim=EMBED_DIM, num_heads=NUM_HEADS, num_slots=NUM_SLOTS)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# Loss and Optimizer\n",
        "# ---------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# ---------------------------\n",
        "# Training Loop\n",
        "# ---------------------------\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for user_emb, video_emb, metadata_emb, slot_id in train_loader:\n",
        "        user_emb, video_emb, metadata_emb, slot_id = user_emb.to(device), video_emb.to(device), metadata_emb.to(device), slot_id.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        slot_scores = model(user_emb, video_emb, metadata_emb)\n",
        "        loss = criterion(slot_scores, slot_id)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, top1_correct, top3_correct = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for user_emb, video_emb, metadata_emb, slot_id in val_loader:\n",
        "            user_emb, video_emb, metadata_emb, slot_id = user_emb.to(device), video_emb.to(device), metadata_emb.to(device), slot_id.to(device)\n",
        "            slot_scores = model(user_emb, video_emb, metadata_emb)\n",
        "            val_loss += criterion(slot_scores, slot_id).item()\n",
        "\n",
        "            probs = torch.softmax(slot_scores, dim=-1)\n",
        "            top1_correct += (probs.argmax(dim=-1) == slot_id).sum().item()\n",
        "            top3_correct += (torch.topk(probs, k=3, dim=-1).indices == slot_id.unsqueeze(1)).any(dim=1).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    top1_acc = top1_correct / len(val_subset)\n",
        "    top3_acc = top3_correct / len(val_subset)\n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {running_loss/len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Top1 Acc: {top1_acc:.4f} | Top3 Acc: {top3_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjXDDCmsYRBQ",
        "outputId": "20302fb1-4a89-48b0-ae23-ce7188124106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to fusion_model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"fusion_model.pth\")\n",
        "print(\"Model saved to fusion_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE5glkWPuQHE"
      },
      "outputs": [],
      "source": [
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/30 14:41:55 INFO mlflow.tracking.fluent: Experiment with name 'FusionModelExperiment_2' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃 View run FusionModelRun_2 at: http://127.0.0.1:5000/#/experiments/870371538631987082/runs/dfebb4ef5f5f4d01975f28b175bc50de\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/870371538631987082\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mnum_slots\u001b[39m\u001b[33m\"\u001b[39m, NUM_SLOTS)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mmodel\u001b[49m.train()\n\u001b[32m     14\u001b[39m     running_loss = \u001b[32m0\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m user_emb, video_emb, metadata_emb, slot_id \u001b[38;5;129;01min\u001b[39;00m train_loader:\n",
            "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "mlflow.set_experiment(\"FusionModelExperiment_3\")\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"FusionModelRun_3\"):\n",
        "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
        "    mlflow.log_param(\"num_epochs\", NUM_EPOCHS)\n",
        "    mlflow.log_param(\"learning_rate\", LEARNING_RATE)\n",
        "    mlflow.log_param(\"embed_dim\", EMBED_DIM)\n",
        "    mlflow.log_param(\"num_heads\", NUM_HEADS)\n",
        "    mlflow.log_param(\"num_slots\", NUM_SLOTS)\n",
        "\n",
        "    mlflow.pytorch.log_model(model, \"fusion_model\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for user_emb, video_emb, metadata_emb, slot_id in train_loader:\n",
        "            user_emb, video_emb, metadata_emb, slot_id = user_emb.to(device), video_emb.to(device), metadata_emb.to(device), slot_id.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            slot_scores = model(user_emb, video_emb, metadata_emb)\n",
        "            loss = criterion(slot_scores, slot_id)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, top1_correct, top3_correct = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for user_emb, video_emb, metadata_emb, slot_id in val_loader:\n",
        "                user_emb, video_emb, metadata_emb, slot_id = user_emb.to(device), video_emb.to(device), metadata_emb.to(device), slot_id.to(device)\n",
        "                slot_scores = model(user_emb, video_emb, metadata_emb)\n",
        "                val_loss += criterion(slot_scores, slot_id).item()\n",
        "\n",
        "                probs = torch.softmax(slot_scores, dim=-1)\n",
        "                top1_correct += (probs.argmax(dim=-1) == slot_id).sum().item()\n",
        "                top3_correct += (torch.topk(probs, k=3, dim=-1).indices == slot_id.unsqueeze(1)).any(dim=1).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        top1_acc = top1_correct / len(val_subset)\n",
        "        top3_acc = top3_correct / len(val_subset)\n",
        "\n",
        "        mlflow.log_metric(\"train_loss\", running_loss/len(train_loader), step=epoch)\n",
        "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "        mlflow.log_metric(\"top1_acc\", top1_acc, step=epoch)\n",
        "        mlflow.log_metric(\"top3_acc\", top3_acc, step=epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {running_loss/len(train_loader):.4f} | Val Loss: {val_loss:.4f} | Top1 Acc: {top1_acc:.4f} | Top3 Acc: {top3_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
